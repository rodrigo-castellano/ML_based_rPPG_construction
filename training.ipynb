{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook does the training of the models. Options to do cross validation and hyperparameter search. \n",
    "\n",
    "The modules used in this notebook are imported below. \n",
    "\n",
    "- The module utils_model contains auxiliary files for the model.\n",
    "- The module network contains different neural network architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model.data_helper import *\n",
    "from utils_model.model_utils import *\n",
    "from utils_model.visualization import *\n",
    "from utils_model.process_bpm import *\n",
    "from utils_model.eval_methods import *\n",
    "from utils_model.data_prep_model import *\n",
    "from network import LSTM as MyModel\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sktime.distances import dtw_distance\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose params and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the paramters for the model\n",
    "params = {\n",
    "            'epochs':[1500],\n",
    "            'batch_size':[24],\n",
    "            'lr_scheduler':['plateau'],\n",
    "            'units': [[90,60,30,1],[60,30,1],[120,90,60,30,1]],  \n",
    "            'loss':['custom'], \n",
    "            'metrics':[['r','rmse','mse']],\n",
    "            'optimizer':['adam'], \n",
    "            'datasets': [[ 'PURE']], \n",
    "            'datasets_only_test':[[]],\n",
    "            'methods_list': [['gt','cpu_LGI','cpu_CHROM','cpu_POS','cpu_ICA']], \n",
    "            'landmarks':['combined'],\n",
    "            'fps' : [30],\n",
    "            'win_secs':[10,5],\n",
    "            'norm':['min_max'],\n",
    "            'act_filter':['all'], # resting, resting+, all \n",
    "            'dropout':[.2],  \n",
    "            'K_fold':[5],\n",
    "            'early_stopping':[False],\n",
    "            'overlap':[150,0],\n",
    "}\n",
    "\n",
    "param_grid = ParameterGrid(params)\n",
    "\n",
    "# This is in case we want to run only one experiment\n",
    "param = param_grid[0]\n",
    "param['samples'] = int(param['fps']*param['win_secs'])\n",
    "param['n_methods'] = len(param['methods_list'])-1\n",
    "landmarks = select_landmarks(param['landmarks'])\n",
    "param['n_landmarks'] = len(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset  ['PURE']\n"
     ]
    }
   ],
   "source": [
    "# Load and process data from all datasets\n",
    "data, fps = load_dataset('.\\\\pyVHR\\\\datasets',param['datasets'])\n",
    "data_no_window = copy.deepcopy(data)\n",
    "data = clean_landmarks(data)\n",
    "data = resample_gt(data)\n",
    "data = split_dataset_windows(data, param['win_secs'], fps, overlap=param['overlap'])\n",
    "data = resample_windows(data,param['win_secs'],param['fps'])\n",
    "data = norm_windows(data, mode=param['norm'],dim=3)\n",
    "data = clean_windowed_dataset(data)\n",
    "data = hist_equalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and test splits, and the names of the subjects in each of the splits\n",
    "data_splits,names_splits,param = process(param,copy.deepcopy(data),ground_truth='gt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_splits[0]['x_train']\n",
    "x_test = data_splits[0]['x_test']\n",
    "y_train = data_splits[0]['y_train']\n",
    "y_test = data_splits[0]['y_test']\n",
    "model = MyModel(param['samples'],param['n_methods'],param['n_landmarks'],drop=param['dropout'],units=param['units'])\n",
    "model.build((None,param['samples'], param['n_methods']*param['n_landmarks']))\n",
    "model.layers[0].summary()\n",
    "model,history = run_model(model,param,x_train,x_test,y_train,y_test,write_dir=True,save_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-FOLD CV\n",
    "models0 = []\n",
    "histories0 = []\n",
    "for i in range(len(data_splits)):\n",
    "    print('Number',i+1,'/',len(data_splits))\n",
    "    # from data_splits, get the data for each fold\n",
    "    x_train = data_splits[0]['x_train']\n",
    "    x_test = data_splits[0]['x_test']\n",
    "    y_train = data_splits[0]['y_train']\n",
    "    y_test = data_splits[0]['y_test']\n",
    "\n",
    "    model = MyModel(param['samples'],param['n_methods'],param['n_landmarks'],drop=param['dropout'],units=param['units'])\n",
    "    # model.build((None,param['samples'], param['n_methods']*param['n_landmarks']))\n",
    "    # model.layers[0].summary()\n",
    "    model,history = run_model(model,param,x_train,x_test,y_train,y_test,write_dir=True,save_plot=True)\n",
    "    models0.append(model)\n",
    "    histories0.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    # K-FOLD CV\n",
    "    models = []\n",
    "    histories = []\n",
    "    for i in range(len(data_splits)):\n",
    "        print('Fold',i+1,'/',len(data_splits))\n",
    "        # from data_splits, get the data for each fold\n",
    "        x_train = data_splits[i]['x_train']\n",
    "        x_test = data_splits[i]['x_test']\n",
    "        y_train = data_splits[i]['y_train']\n",
    "        y_test = data_splits[i]['y_test']\n",
    "\n",
    "        model = MyModel(param['samples'],param['n_methods'],param['n_landmarks'],drop=param['dropout'],units=param['units'])\n",
    "        # model.build((None,param['samples'], param['n_methods']*param['n_landmarks']))\n",
    "        # model.layers[0].summary()\n",
    "        model,history = run_model(model,param,x_train,x_test,y_train,y_test,write_dir=True,save_plot=True)\n",
    "        models.append(model)\n",
    "        histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER TUNING\n",
    "\n",
    "all_acc = [] # to find later the setting with highest acc\n",
    "for i,param in enumerate(param_grid):\n",
    "    param['samples'] = int(param['fps']*param['win_secs'])\n",
    "    param['n_methods'] = len(param['methods_list'])-1\n",
    "    landmarks = select_landmarks(param['landmarks'])\n",
    "    param['n_landmarks'] = len(landmarks)\n",
    "\n",
    "    data, fps = load_dataset('.\\\\pyVHR\\\\datasets',param['datasets'])\n",
    "    data_no_window = copy.deepcopy(data)\n",
    "    data = clean_landmarks(data)\n",
    "    data = resample_gt(data)\n",
    "    data = split_dataset_windows(data, param['win_secs'], fps, overlap=param['overlap'])\n",
    "    data = resample_windows(data,param['win_secs'],param['fps'])\n",
    "    data = norm_windows(data, mode=param['norm'],dim=3)\n",
    "    data = clean_windowed_dataset(data)\n",
    "    data = hist_equalize(data)\n",
    "\n",
    "    # Get the train and test splits, and the names of the splits\n",
    "    data_splits,names_splits,param = process(param,copy.deepcopy(data),ground_truth='gt')\n",
    "\n",
    "    x_train = data_splits[0]['x_train']\n",
    "    x_test = data_splits[0]['x_test']\n",
    "    y_train = data_splits[0]['y_train']\n",
    "    y_test = data_splits[0]['y_test']\n",
    "\n",
    "    # if i > 0 :\n",
    "    start_time = time.time()\n",
    "    print('Fit number ',i,'/',len(param_grid))\n",
    "    print('---------------------------------------')\n",
    "    for key in param:\n",
    "        print(key,':',param[key])  \n",
    "    print('---------------------------------------')\n",
    "\n",
    "    model = MyModel(param['samples'],param['n_methods'],param['n_landmarks'],drop=param['dropout'],units=param['units'])\n",
    "    # model.build((None,param['samples'], param['n_methods']*param['n_landmarks']))\n",
    "    # model.layers[0].summary()\n",
    "    model,history = run_model(model,param,x_train,x_test,y_train,y_test,write_dir=True,save_plot=True)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (np.round(time.time() - start_time,2)))\n",
    "    best_val_acc = history.history['val_loss'][-1]\n",
    "    all_acc.append(best_val_acc)\n",
    "\n",
    "best = np.argmin(np.array(all_acc))\n",
    "print('The best combination is the number',best,':',param_grid[best], 'with an accuracy of ',all_acc[best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = np.argmin(np.array(all_acc))\n",
    "print('The best combination is the number',best,':',param_grid[best], 'with an accuracy of ',all_acc[best])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01df460a5a12bfa33a7d613bb157e720ba5f5e81b04876407212320fd31de27a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
